{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook: \"User Research Helper\" on Google Colab\n",
    "\n",
    "This notebook permits you to use the \"user-research-helper\" library directly from GitHub on a Google Drive project. \n",
    "\n",
    "You need to fill in the following cell \n",
    "- the environment variables `OPENAI_API_KEY` and `ASSEMBLYAI_API_KEY` with your own API keys \n",
    "- the variable `DATA_PATH` to indicate the path to your data on your Google Drive. Your data must include interview questions, audio recordings of the interviews, and the interview context.\n",
    "\n",
    "Please refer to the [Data Setup section](https://github.com/nagoli/user-research-helper#51-data-setup) of the README for more details about how to structure your data.\n",
    "\n",
    "Press the Play button ( ▶️ ) at the left of the next cell to execute it : first read the instructions and run the cell sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Enter your OpenAI and AssemblyAI API keys \n",
    "# (you are running this notebook on your Google account, all your changes will remain confidential)\n",
    "OPENAI_API_KEY = \"\" \n",
    "ASSEMBLYAI_API_KEY = \"\" \n",
    "\n",
    "DATA_PATH = \"projectFolder\" # name of the folder below the root MyDrive on your Google Drive \n",
    "\n",
    "# Just run ( ▶️ ) this cell to connect your Google Drive and finish the setup \n",
    "\n",
    "!pip install git+https://github.com/nagoli/user-research-helper.git\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "os.environ['ASSEMBLYAI_API_KEY'] = ASSEMBLYAI_API_KEY\n",
    "print(\"OpenAI and AssemblyAI keys have been set in the Colab environment.\")\n",
    "\n",
    "DATA_PATH = \"/content/drive/MyDrive/\" + DATA_PATH\n",
    "from google.colab import drive ;\n",
    "drive.mount(\"/content/drive\")\n",
    "!ls -l $DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transcript processing \n",
    "Ensure that your data are correctly setup on your google drive then process transcripts and per interview analysis by running the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Run ( ▶️ ) this cell to process interviews\n",
    "from user_research_helper.transcript.process_transcripts import process_transcripts\n",
    "process_transcripts(DATA_PATH)\n",
    "print('')\n",
    "!ls -l $DATA_PATH/analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Segments in the Generated Excel Files\n",
    "\n",
    "- The script should produce `transcript_analysis_report.xlsx` and `transcript_analysis_report_quotes.xlsx` in the `analysis/` directory.\n",
    "\n",
    "- You can open them from Google Drive or download them locally to edit.  \n",
    "- Once you've made segment definition in both, place them back into `analysis/` or the appropriate subfolder.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Report Generation \n",
    "Run the following cell to generate the final cross segment per question analysis report\n",
    "The report will be saved in `analysis/results_with_quotes.docx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Run ( ▶️ ) this cell to launch the analysis\n",
    "from user_research_helper.result_analysis.process_analysis import process_analysis\n",
    "process_analysis(DATA_PATH)\n",
    "print('')\n",
    "!ls -l $DATA_PATH/analysis"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
